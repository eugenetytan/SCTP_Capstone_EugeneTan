{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Used Cars on sgcarmart.com\n",
    "## 1. Introduction\n",
    "\n",
    "### This document outlines the process of web scraping data from sgcarmart.com, the largest online car marketplace in Singapore, to analyze the used car market.\n",
    "\n",
    "### Respecting sgcarmart.com's Rules\n",
    "The scraping script will adhere to the guidelines outlined in sgcarmart.com's robots.txt file. Here's a summary of the restrictions:\n",
    "\n",
    "Crawlers must wait at least 5 seconds between requests (Crawl-delay: 5).\n",
    "Specific directories are off-limits for scraping, including:\n",
    "cgi-bin/\n",
    "images/\n",
    "mail/\n",
    "dealer/\n",
    "directory/premium/\n",
    "includes/\n",
    "phpads/\n",
    "update/\n",
    "upload/\n",
    "\n",
    "### Data Extraction\n",
    "The script will focus on extracting the following information for each used car listing:\n",
    "\n",
    "Car Listing URL 'LISTING_URL', \n",
    "Car Brand and Model 'BRAND', \n",
    "Price 'PRICE', \n",
    "Depreciation Value Yearly 'DEPRE_VALUE_PER_YEAR', \n",
    "Registered Date 'REG_DATE', \n",
    "Mileage in KM 'MILEAGE_KM', \n",
    "Year of Manufacture 'MANUFACTURED_YEAR', \n",
    "Road Tax Yearly 'ROAD_TAX_PER_YEAR', \n",
    "Automatic or Manual Tranmission 'TRANSMISSION', \n",
    "Deregistration Value as of Web Scraping DTD 'DEREG_VALUE_FROM_SCRAPE_DATE', \n",
    "Web Scraping DTD 'SCRAPE_DATE', \n",
    "Open Market Value (OMV) 'OMV', \n",
    "Additional Registration Fee (ARF) 'ARF', \n",
    "Certificate of Entitlement (COE) from Web Scraping DTD 'COE_FROM_SCRAPE_DATE', \n",
    "Number of Days till COE Expires 'DAYS_OF_COE_LEFT', \n",
    "Engine Capacity in CC 'ENGINE_CAPACITY_CC', \n",
    "Car Curb Weight in KG 'CURB_WEIGHT_KG', \n",
    "Number of Past Owners 'NO_OF_OWNERS', \n",
    "Vehicle Type 'VEHICLE_TYPE'\n",
    "\n",
    "This data will be used for further analysis of the used car market in Singapore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All retriever functions take a parsed individual car lsting url and returns a desired attribute named after the function\n",
    "\n",
    "\n",
    "# Brand Retriever Function \n",
    " \n",
    "def brand_retrieval(parsed_url):\n",
    "    # Find the <a> tag with the \"nounderline globaltitle\" class\n",
    "    brand_tag = parsed_url.find(\"a\", class_=\"nounderline globaltitle\")\n",
    "    \n",
    "    if brand_tag:\n",
    "        # Extract the brand name from the href attribute\n",
    "        brand_name = brand_tag[\"href\"].split(\"=\")[1].replace(\"+\", \" \").split(\"&\")[0]\n",
    "        return brand_name\n",
    "    else:\n",
    "        brand_name = np.nan  # Stores NA values as nan\n",
    "    \n",
    "    return brand_name\n",
    "    \n",
    "# Price Retriever Function\n",
    "\n",
    "def price_error_handling(data_value):\n",
    "    # Try-Exception error handling\n",
    "    \n",
    "    try:   # First try to deal with values higher than 1000\n",
    "        price = data_value[1]  # will fail on IndexError if retrieves ['na'] scenario\n",
    "        price = int(price.split(',')[0] + price.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        \n",
    "    except IndexError:  # Dealing with ['na'] and ['', 900'] scenarios\n",
    "        try: \n",
    "            price = int(data_value[1]) # Will fail on IndexError if ['na'] scenario\n",
    "        except IndexError:  # Deals with ['na'] scenarios\n",
    "            price = np.nan  # Stores NA values as nan\n",
    "    \n",
    "    return price\n",
    "\n",
    "def price_retrieval(parsed_listing_url):\n",
    "    \n",
    "    data_value = parsed_listing_url.find_all(class_=\"font_red\")[0].text.strip()\n",
    "    data_value = data_value.split('$')\n",
    "    price = price_error_handling(data_value)\n",
    "    return price\n",
    "\n",
    "# Deprecration Value Per Year Retriever Function\n",
    "def depreciation_value_per_year_error_handler(data_value):\n",
    "    if len(data_value) < 2:\n",
    "        data_value = np.nan\n",
    "\n",
    "    else: \n",
    "        data_value = data_value[1].split('/yr')\n",
    "        try:                 \n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                data_value[0].split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['900','']\n",
    "        except IndexError: \n",
    "            desired_value = int(data_value[0])\n",
    "        \n",
    "        return desired_value\n",
    "    \n",
    "def depreciation_value_per_year_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_=\"label\")[1].findNextSibling().text.strip().split('$')\n",
    "    depreciation_value_per_year = depreciation_value_per_year_error_handler(data_value)\n",
    "    return depreciation_value_per_year\n",
    "\n",
    "# Road Tax Per Year Retriever\n",
    "def road_tax_error_handler(string_data):\n",
    "    if '/yr' in string_data: # Only takes in scenarios that are not NA\n",
    "        try:\n",
    "            # Removes '$\" character and splits string_data into a list of ['', 1,000] or ['', 900]\n",
    "            road_tax_per_year = \\\n",
    "            string_data.replace('/yr','').strip().split('$') \n",
    "\n",
    "            # Accesses the second item in the list\n",
    "            road_tax_per_year = road_tax_per_year[1] \n",
    "\n",
    "\n",
    "            road_tax_per_year = int(road_tax_per_year.split(',')[0] +\\\n",
    "                                    road_tax_per_year.split(',')[1])  # Will fail on IndexError if value is above 1000\n",
    "\n",
    "        except IndexError: # Handles values that are below 1000. (i.e. ['',900])\n",
    "            road_tax_pear_year = int(road_tax_per_year[1])\n",
    "\n",
    "    else: # Deals with 'NA' scenario\n",
    "        road_tax_per_year = np.nan\n",
    "    \n",
    "    return road_tax_per_year\n",
    "\n",
    "def road_tax_retrieval(parsed_listing_url):\n",
    "    string_data = parsed_listing_url.find_all(class_='row_info')[1].text.strip()\n",
    "    road_tax_yearly = road_tax_error_handler(string_data)\n",
    "    \n",
    "    return road_tax_yearly\n",
    "    \n",
    "\n",
    "# Registered Date Retriever\n",
    "def registered_date_retrieval(parsed_listing_url):\n",
    "    reg_date = parsed_listing_url.find_all(class_='row_bg')[1].find_all('td')[3].text.split()[0].split('(')[0]\n",
    "    return reg_date\n",
    "\n",
    "# Days of COE Retriever\n",
    "def days_of_coe_retrieval(parsed_listing_url):\n",
    "    days_of_coe_left_yy_mm_dd_format_for_cleaner_function=\\\n",
    "    parsed_listing_url.find_all(class_='row_bg')[1].find_all('td')[3].text.split('(')[1].split('COE')[0].strip()\n",
    "    \n",
    "    return yr_mm_dd_cleaner(days_of_coe_left_yy_mm_dd_format_for_cleaner_function)\n",
    "\n",
    "\n",
    "# Define a function to calculate days of COE left\n",
    "def yr_mm_dd_cleaner(str1):\n",
    "    \"\"\"Accepts a string that may or may include the elements yr mths days and \n",
    "    converts the whole string into number of days.\n",
    "    ----\n",
    "    Input: single string\n",
    "    output: number of days in integer form\n",
    "    ----\n",
    "    Example string inputs:\n",
    "    - 4yrs 2mths 23days\n",
    "    - 5yrs\n",
    "    - 2 mths 23 days\n",
    "    - 50 days\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert days_of_coe_left_yy_mm_dd to days    \n",
    "    year_index = str1.find('yr')\n",
    "    if year_index == -1:\n",
    "        year = 0\n",
    "    else:\n",
    "        year = int(str1[year_index-1])\n",
    "\n",
    "        \n",
    "    mth_index = str1.find('mth')\n",
    "    if mth_index == -1:\n",
    "        mth = 0\n",
    "    else:\n",
    "        mth = int(str1[mth_index-1])\n",
    "\n",
    "        \n",
    "    day_index = str1.find('day')\n",
    "    if day_index == -1:\n",
    "        day = 0\n",
    "    else:\n",
    "        day = int(str1[day_index-1])\n",
    "       \n",
    "    days_of_coe_left = (year * 365) + (mth * 30) + day \n",
    "    return days_of_coe_left\n",
    "\n",
    "\n",
    "# Mileage Retriever\n",
    "def mileage_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['na'] scenarios\n",
    "        mileage_km = np.nan  # Stores NA values as nan\n",
    "\n",
    "    else:  \n",
    "        try:                 \n",
    "            mileage_km = int(data_value[0].strip().split(',')[0] + data_value[0].strip().split(',')[1])\n",
    "        except IndexError: # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "            mileage_km = int(data_value[0].strip())\n",
    "    \n",
    "    return mileage_km\n",
    "\n",
    "def mileage_retrieval(parsed_listing_url):\n",
    "        \n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[0].text.strip()\n",
    "    data_value = data_value.split('km')\n",
    "    mileage_km = mileage_error_handler(data_value)\n",
    "    \n",
    "    return mileage_km\n",
    "\n",
    "# Manufactured Year Retriever\n",
    "def manufactured_year_retrieval(parsed_listing_url):\n",
    "    manufactured_year = parsed_listing_url.find_all(class_='row_info')[6].text.strip()\n",
    "    return manufactured_year.split()[0]\n",
    "\n",
    "# Transmission Retriever\n",
    "def transmission_retrieval(parsed_listing_url):\n",
    "    transmission = parsed_listing_url.find_all(class_='row_info')[7].text.strip()\n",
    "    return transmission.split()[0]\n",
    "\n",
    "# Deregistration Value Retriever\n",
    "def dereg_value_retrieval(parsed_listing_url):\n",
    "    # Splits into ['NA'], or ['$11,026', 'as', 'of', 'today', '(change)'] or ['$900', 'as', 'of', 'today', '(change)']\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[2].text.strip().split() \n",
    "    \n",
    "    dereg_value_from_scrape_date = dereg_value_error_handler(data_value)\n",
    "    return dereg_value_from_scrape_date\n",
    "    \n",
    "\n",
    "def dereg_value_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # Deals with ['NA'] scenario\n",
    "        dereg_value_from_scrape_date = np.nan\n",
    "\n",
    "    else: \n",
    "        data_value = data_value[0].split('$')[1] # Puts input into '11,026' or '900' format\n",
    "        try:                 \n",
    "            dereg_value_from_scrape_date = \\\n",
    "            int(data_value.split(',')[0] +\\\n",
    "                data_value.split(',')[1]) # Will fail on IndexError if tries to split '900' with a ',' in ['',900]\n",
    "        except IndexError: \n",
    "            dereg_value_from_scrape_date = int(data_value.strip())\n",
    "\n",
    "        return dereg_value_from_scrape_date\n",
    "\n",
    "\n",
    "# Open Market Value Retriever\n",
    "def omv_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        omv = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            omv = int(data_value[1].split(',')[0] +\\\n",
    "                      data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            omv = int(data_value[1])\n",
    "    return omv\n",
    "\n",
    "\n",
    "def omv_retrieval(parsed_listing_url):    \n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[8].text.split('$') \n",
    "    # Splits data into ['', '21,967'], ['','900'] or ['NA'] format for input into error function\n",
    "    \n",
    "    omv = omv_error_handler(data_value)\n",
    "    return omv     \n",
    "\n",
    "# ARF Retriever\n",
    "def error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[1].split(',')[0] +\\\n",
    "                                data_value[1].split(',')[1])   # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[1])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def arf_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[9].text.split('$')\n",
    "    arf = error_handler(data_value)\n",
    "    return arf\n",
    "\n",
    "# COE Price retriever \n",
    "def coe_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        coe_from_scrape_date = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            coe_from_scrape_date = int(data_value[1].split(',')[0] +\\\n",
    "                                       data_value[1].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            coe_from_scrape_date = int(data_value[1])\n",
    "    return coe_from_scrape_date\n",
    "\n",
    "\n",
    "def coe_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[3].text.split('$')\n",
    "    coe_from_scrape_date = coe_error_handler(data_value)\n",
    "    return coe_from_scrape_date\n",
    "\n",
    "# Engine Capacity Retriever\n",
    "def engine_capacity_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def engine_capacity_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[4].text.strip().split('cc')\n",
    "    engine_capacity = engine_capacity_error_handler(data_value)\n",
    "    return engine_capacity\n",
    "\n",
    "# Curb Weight Retriever\n",
    "def curb_weight_error_handler(data_value):\n",
    "    if len(data_value) < 2:  # deals iwth ['NA'] input\n",
    "        desired_value = np.nan\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            desired_value = int(data_value[0].split(',')[0] +\\\n",
    "                                       data_value[0].split(',')[1])  # Will fail on index error if try to split 900\n",
    "        except IndexError:\n",
    "            desired_value = int(data_value[0])\n",
    "    return desired_value\n",
    "\n",
    "\n",
    "def curb_weight_retrieval(parsed_listing_url):\n",
    "    data_value = parsed_listing_url.find_all(class_='row_info')[5].text.split()\n",
    "    curb_weight = curb_weight_error_handler(data_value)\n",
    "    return curb_weight\n",
    "\n",
    "# Number of owners retriever\n",
    "def number_of_owners_retrieval(parsed_listing_url):\n",
    "    no_of_owners = int(parsed_listing_url.find_all(class_='row_info')[-1].text)\n",
    "    return no_of_owners\n",
    "\n",
    "\n",
    "# Type of Vehicle Retriever\n",
    "def type_of_vehicle_retrieval(parsed_listing_url):\n",
    "    type_of_vehicle = parsed_listing_url.find(class_='row_bg1').find_all('a')[0].text \n",
    "    return type_of_vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Links For All Postings\n",
    "\n",
    "Links for all the car postings will be stored in a list before accessing them one by one for data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create listings URLs to iterate through\n",
    "main_page_listing_list = [] # create list to store search pages\n",
    "for idx, link in enumerate(range(100)):\n",
    "    url = \"https://www.sgcarmart.com/used_cars/listing.php?BRSR=\" + str(idx * 100) + \"&RPG=100&AVL=2&VEH=2\" #search by of 100 car listings per page\n",
    "    main_page_listing_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.sgcarmart.com/used_cars/listing.php?BRSR=0&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=1900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=2900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=3900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=4900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=5900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=6900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=7900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=8900&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9000&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9100&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9200&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9300&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9400&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9500&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9600&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9700&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9800&RPG=100&AVL=2&VEH=2', 'https://www.sgcarmart.com/used_cars/listing.php?BRSR=9900&RPG=100&AVL=2&VEH=2'] \n",
      " \n",
      " 100\n"
     ]
    }
   ],
   "source": [
    "print(main_page_listing_list,'\\n','\\n', len(main_page_listing_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieval of Individual Listing URLs from Search Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base url, or you can think of this as the individual car listing prefix\n",
    "base_url = 'https://www.sgcarmart.com/used_cars/'\n",
    "listing_urls = []\n",
    "\n",
    "# Acquiring indvidual car listings    \n",
    "for main_link in main_page_listing_list:\n",
    "   \n",
    "    # Make a request to the website and get the object\n",
    "    content = requests.get(main_link)\n",
    "\n",
    "    # Parse the HTML text\n",
    "    soup = BeautifulSoup(content.text, 'lxml')\n",
    "\n",
    "    # Find every single URL in the webpage , refer to this post: # https://stackoverflow.com/questions/46490626/getting-all-links-from-a-page-beautiful-soup\n",
    "    # This returns a list of every tag that contains a link in one main link (each element in main page listing)\n",
    "    links = soup.find_all('a')\n",
    "    \n",
    "    # Create a list for storing all the individual listing urls\n",
    "    \n",
    "    for link in links:\n",
    "        # Get link in <a href>\n",
    "        suffix = link.get('href')\n",
    "\n",
    "        # Check if 'ID=' and 'DL=' exist in the string\n",
    "        if ('ID=' in suffix) and ('DL=' in suffix):\n",
    "\n",
    "            # Concatenate the two strings if they do\n",
    "            listing_url = base_url + suffix\n",
    "        #    print(listing_url)\n",
    "            \n",
    "            # Append result to the list\n",
    "            listing_urls.append(listing_url)\n",
    "            \n",
    "#     Removing duplicates\n",
    "    set_listing_urls = set(listing_urls)\n",
    "    listing_urls = list(set_listing_urls)\n",
    "    \n",
    "    # Prevent oneself from getting blocked from the website\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(listing_urls))\n",
    "print(len(set(listing_urls)))\n",
    "print(len(list(set(listing_urls))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listing_urls[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame for attributes of interest\n",
    "df = pd.DataFrame(columns=['LISTING_URL', 'BRAND', 'PRICE', 'DEPRE_VALUE_PER_YEAR',\n",
    "       'REG_DATE', 'MILEAGE_KM', 'MANUFACTURED_YEAR',\n",
    "       'ROAD_TAX_PER_YEAR','TRANSMISSION', 'DEREG_VALUE_FROM_SCRAPE_DATE',\n",
    "       'SCRAPE_DATE', 'OMV', 'ARF', 'COE_FROM_SCRAPE_DATE',\n",
    "       'DAYS_OF_COE_LEFT', 'ENGINE_CAPACITY_CC', 'CURB_WEIGHT_KG',\n",
    "       'NO_OF_OWNERS', 'VEHICLE_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sgcarmart_used_cars_prices'\n",
    "i = 0 # Indexing rows in the DF\n",
    "\n",
    "for listingurl in listing_urls:\n",
    "    response = requests.get(listingurl)\n",
    "    listing_url = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    print(listing_url)\n",
    "\n",
    "    # Retrieval functions to pull data from the Individual Listings after they have been parsed\n",
    "    df.loc[i, 'LISTING_URL'] = listingurl\n",
    "    df.loc[i, 'BRAND'] = brand_retrieval(listing_url)\n",
    "    df.loc[i, 'PRICE'] = price_retrieval(listing_url)\n",
    "    try:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = depreciation_value_per_year_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DEPRE_VALUE_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'REG_DATE'] = registered_date_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'REG_DATE'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'MILEAGE_KM'] = mileage_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'MILEAGE_KM'] = np.nan\n",
    "\n",
    "    try:\n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = manufactured_year_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'MANUFACTURED_YEAR'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = road_tax_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'ROAD_TAX_PER_YEAR'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'TRANSMISSION'] = transmission_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'TRANSMISSION'] = np.nan\n",
    "\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = dereg_value_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'DEREG_VALUE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    df.loc[i, 'SCRAPE_DATE'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    try:\n",
    "        df.loc[i, 'OMV'] = omv_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'OMV'] = np.nan\n",
    "\n",
    "    try:\n",
    "        df.loc[i, 'ARF'] = arf_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ARF'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'COE_FROM_SCRAPE_DATE'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = days_of_coe_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'DAYS_OF_COE_LEFT'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = engine_capacity_retrieval(listing_url)\n",
    "    except: \n",
    "        df.loc[i, 'ENGINE_CAPACITY_CC'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = curb_weight_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'CURB_WEIGHT_KG'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = number_of_owners_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'NO_OF_OWNERS'] = np.nan\n",
    "        \n",
    "    try:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = type_of_vehicle_retrieval(listing_url)\n",
    "    except:\n",
    "        df.loc[i, 'VEHICLE_TYPE'] = np.nan\n",
    "        \n",
    "    df.to_csv(\"{}.csv\".format(filename))    \n",
    "        \n",
    "    i += 1 # Allows next car listing to be put into a next row in the dataframe\n",
    "    time.sleep(5)  # Prevents us from getting locked out of the website\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sgcarmart_used_cars_prices.csv',index_col=0)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
